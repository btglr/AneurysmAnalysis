{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection, Segmentation et Analyse d'Anévrismes Cérébraux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Plusieurs paquets sont nécessaires pour exécuter le script en lui-même ainsi que le notebook.\n",
    "\n",
    "`pip install pydicom ipympl opencv-python scikit-image scipy`\n",
    "\n",
    "Afin d'exécuter le script Python avec l'interface complète, il faut exécuter la commande suivante :\n",
    "\n",
    "`python main.py`\n",
    "\n",
    "Le dossier ImgTP doit se trouver à la racine du dossier où se trouve main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import copy\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interactive\n",
    "from IPython.display import display, clear_output, HTML, Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture du DICOMDIR et traitement des images\n",
    "\n",
    "Dans un premier temps, nous avons recherché un outil en Python capable de lire des fichiers DICOM et d'en extraire les informations nécessaires. Le paquet `pydicom` permet ceci.\n",
    "\n",
    "<!-- Description de l'installation -->\n",
    "\n",
    "Une fois ce paquet installé, nous pouvons lire notre jeu de données. Celui-ci contient des informations à plusieurs niveaux : pour chaque patient, il peut y avoir une ou plusieurs expérience(s) contenant chacune une ou plusieurs série(s) d'images. Dans notre cas, nous n'avons qu'une seule série. Nous récupérons les chemins de ces images puis les lisons avec la fonction `dcmread` du paquet `pydicom`.\n",
    "\n",
    "<!-- On a remarqué que sur les 500 et quelques images qu'on a, il y a une répétition toutes les 48 images -->\n",
    "\n",
    "Ces images sont en niveaux de gris sur 16 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"ImgTP/Ge1CaroG/MR_3DPCA\"\n",
    "ds = load_dataset(dataset_path)\n",
    "\n",
    "# 0018,1090  Cardiac Number of Images: 12\n",
    "nb_image_sets = 12\n",
    "\n",
    "# Select the first image set (must be < 12)\n",
    "starting_image_set = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# Iterate through the PATIENT records\n",
    "for patient in ds.patient_records:\n",
    "    # Find all the STUDY records for the patient\n",
    "    studies = [ii for ii in patient.children if ii.DirectoryRecordType == \"STUDY\"]\n",
    "\n",
    "    for study in studies:\n",
    "        # Find all the SERIES records in the study\n",
    "        all_series = [ii for ii in study.children if ii.DirectoryRecordType == \"SERIES\"]\n",
    "\n",
    "        for series in all_series:\n",
    "            # Find all the IMAGE records in the series\n",
    "            images = [ii for ii in series.children if ii.DirectoryRecordType == \"IMAGE\"]\n",
    "\n",
    "            # Get the absolute file path to each instance\n",
    "            # Each IMAGE contains a relative file path to the root directory\n",
    "            elems = [ii[\"ReferencedFileID\"] for ii in images]\n",
    "            # Make sure the relative file path is always a list of str\n",
    "            paths = [[ee.value] if ee.VM == 1 else ee.value for ee in elems]\n",
    "            paths = [Path(*p) for p in paths]\n",
    "\n",
    "            images = []\n",
    "\n",
    "            i = 0\n",
    "\n",
    "            total_images = len(paths)\n",
    "            max_images = int(total_images / nb_image_sets)\n",
    "\n",
    "            # List the instance file paths\n",
    "            for idx in range(starting_image_set * max_images, (starting_image_set + 1) * max_images):\n",
    "                p = paths[idx]\n",
    "                img = dcmread(Path(dataset_path).joinpath(p))\n",
    "                images.append((img, p))\n",
    "\n",
    "            data['images'] = images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression du bruit\n",
    "\n",
    "### Explications\n",
    "\n",
    "La suppression du bruit peut s'effectuer par l'utilisation de différents filtres. Parmi ceux-ci on retrouve par exemple le filtre bilatéral, le débruitage par patchs (Non-Local Means) ou encore le filtre médian.\n",
    "\n",
    "### Déclaration des fonctions\n",
    "\n",
    "Nous utilisons ici les fonctions mises à disposition par skimage et scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_nl_means, estimate_sigma, denoise_bilateral\n",
    "\n",
    "def apply_simple_denoise(img, denoise_filter=ndimage.median_filter, kernel_size=3):\n",
    "    new_img = denoise_filter(img.pixel_array, kernel_size)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def apply_non_local_means(img, kernel=5, window_search=13):\n",
    "    # Retain original data type\n",
    "    orig_dtype = img.pixel_array.dtype\n",
    "\n",
    "    # Convert from [0; max] to [0; 1] as it is required by denoise_nl_means\n",
    "    upper_bound = np.max(img.pixel_array)\n",
    "    img_as_float = img.pixel_array / upper_bound\n",
    "\n",
    "    sigma_est = np.mean(estimate_sigma(img_as_float, multichannel=False))\n",
    "\n",
    "    new_img = denoise_nl_means(img_as_float, h=sigma_est, fast_mode=True, patch_size=kernel,\n",
    "                               patch_distance=window_search)\n",
    "\n",
    "    # Convert back to [0; max]\n",
    "    new_img *= upper_bound\n",
    "\n",
    "    return new_img.astype(orig_dtype)\n",
    "\n",
    "\n",
    "def apply_bilateral_filtering(img, d=15, sigmacolor=75, sigmacoordinate=75):\n",
    "    # Retain original data type\n",
    "    orig_dtype = img.pixel_array.dtype\n",
    "\n",
    "    # Convert from [0; max] to [0; 1] as it is required by denoise_bilateral\n",
    "    upper_bound = np.max(img.pixel_array)\n",
    "    img_as_float = img.pixel_array / upper_bound\n",
    "\n",
    "    new_img = denoise_bilateral(img_as_float, win_size=d, sigma_color=sigmacolor, sigma_spatial=sigmacoordinate)\n",
    "\n",
    "    # Convert back to [0; max]\n",
    "    new_img *= upper_bound\n",
    "\n",
    "    return new_img.astype(orig_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque image, on effectue la suppression du bruit avec chacun des filtres précédemment cités puis on stocke toutes ces nouvelles images afin de les afficher et les comparer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "images = data['images']\n",
    "denoised_images = {}\n",
    "\n",
    "median_images = []\n",
    "bilateral_images = []\n",
    "non_local_images = []\n",
    "\n",
    "for image, p in images:\n",
    "    median = apply_simple_denoise(image, kernel_size=3)\n",
    "    bilateral = apply_bilateral_filtering(image, 4, 35, 35)\n",
    "    non_local = apply_non_local_means(image)\n",
    "\n",
    "    median_images.append(median)\n",
    "    bilateral_images.append(bilateral)\n",
    "    non_local_images.append(non_local)\n",
    "\n",
    "denoised_images['median'] = median_images\n",
    "denoised_images['bilateral'] = bilateral_images\n",
    "denoised_images['non_local'] = non_local_images\n",
    "\n",
    "data['denoised_images'] = denoised_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des résultats de suppression de bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hideCode": true,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2badd3a6ba54bfeba2435bbe5458380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), IntSlider(value=0, description='Image', layout=Layout(width='99%'), max=47), FloatSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_sets = [\n",
    "    {\n",
    "        'images': [image.pixel_array for image, _ in data['images']],\n",
    "        'title': 'Original',\n",
    "        'shown': True\n",
    "    },\n",
    "    {\n",
    "        'images': data['denoised_images']['median'],\n",
    "        'title': 'Median Filter',\n",
    "        'shown': True\n",
    "    },\n",
    "    {\n",
    "        'images': data['denoised_images']['bilateral'],\n",
    "        'title': 'Bilateral Filter',\n",
    "        'shown': True\n",
    "    },\n",
    "    {\n",
    "        'images': data['denoised_images']['non_local'],\n",
    "        'title': 'Non Local Means',\n",
    "        'shown': True\n",
    "    }\n",
    "]\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "fig = None\n",
    "\n",
    "with output:\n",
    "    plt.close(fig)\n",
    "    fig = plt.figure()\n",
    "\n",
    "# Hide figure header\n",
    "fig.canvas.header_visible = False\n",
    "ls = []\n",
    "current_image_slider = 0\n",
    "shown_image_sets = [image_set for image_set in image_sets if image_set['shown']]\n",
    "zoom = 2\n",
    "output_h, output_w = 0, 0\n",
    "\n",
    "# Executed on image slider change\n",
    "def update_images(change):\n",
    "    global shown_image_sets, ls\n",
    "    current_image_slider = change.new\n",
    "\n",
    "    for idx, image in enumerate(ls):\n",
    "        image.set_data(shown_image_sets[idx]['images'][change.new])\n",
    "\n",
    "\n",
    "# Executed on zoom slider change\n",
    "def update_zoom(change):\n",
    "    global zoom, fig\n",
    "    zoom = change.new\n",
    "    fig.set_size_inches(output_w * zoom / 100, output_h * zoom / 100, forward=True)\n",
    "\n",
    "\n",
    "def plot_images(fig, image_sets):\n",
    "    global shown_image_sets, output_h, output_w\n",
    "    shown_image_sets = [image_set for image_set in image_sets if image_set['shown']]\n",
    "    nb_shown_image_sets = len(shown_image_sets)\n",
    "\n",
    "    ncols = 4\n",
    "    nrows = int(np.ceil(nb_shown_image_sets / float(ncols)))\n",
    "    height, width = shown_image_sets[0]['images'][0].shape\n",
    "    output_h, output_w = (height * nrows), (width * ncols)\n",
    "\n",
    "    # Clear previous figure\n",
    "    fig.clf()\n",
    "    # Set figure size based on the number of image sets\n",
    "    fig.set_size_inches(output_w * zoom / 100, output_h * zoom / 100, forward=True)\n",
    "    fig.set_dpi(100)\n",
    "\n",
    "    for idx in range(nb_shown_image_sets):\n",
    "        ax = fig.add_subplot(nrows, ncols, idx + 1)\n",
    "        image = ax.imshow(shown_image_sets[idx]['images'][current_image_slider], cmap=plt.cm.gray)\n",
    "        ls.append(image)\n",
    "\n",
    "        # Set title\n",
    "        ax.title.set_text(shown_image_sets[idx]['title'])\n",
    "\n",
    "        # Hide grid and x, y ticks\n",
    "        ax.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "image_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0, max=47, step=1,\n",
    "    continuous_update=True,\n",
    "    description='Image',\n",
    "    layout=widgets.Layout(width='99%')\n",
    ")\n",
    "\n",
    "zoom_slider = widgets.FloatSlider(\n",
    "    value=zoom,\n",
    "    min=1, max=3, step=0.1,\n",
    "    continuous_update=False,\n",
    "    description='Zoom',\n",
    "    layout=widgets.Layout(width='99%')\n",
    ")\n",
    "\n",
    "image_slider.observe(update_images, 'value')\n",
    "zoom_slider.observe(update_zoom, 'value')\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_images(fig, shown_image_sets)\n",
    "\n",
    "widgets.VBox([output, image_slider, zoom_slider])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![\"Denoising Example\"](examples/denoising_example.png) -->\n",
    "\n",
    "### Exemple de suppression du bruit sur l'image 16\n",
    "\n",
    "<img src=\"examples/denoising_example.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le filtre bilatéral semble flouter les contours tandis que le filtre Non-Local Means réduit moins bien le bruit que le filtre médian. On utilisera par la suite uniquement les résultats obtenus par le filtre médian.\n",
    "\n",
    "Ce filtre réduit relativement bien le bruit tout en conservant les contours. Il est ici utilisé avec un kernel de taille 3x3.\n",
    "\n",
    "<!-- Explication de pourquoi on utilise le filtre médian (meilleurs résultats, maintien des contours, ...) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation du réseau vasculaire cérébral\n",
    "\n",
    "Une fois le bruit supprimé de nos images, nous pouvons passer à la segmentation. Notre but est d'extraire les deux carotides et le tronc basilaire de nos images.\n",
    "\n",
    "Cette fois encore, plusieurs possibilités : la segmentation par seuillage (Threshold), par marche aléatoire (Random Walker) ou par remplissage par diffusion (Flood Fill)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déclaration des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import random_walker\n",
    "\n",
    "def apply_random_walker(image):\n",
    "    upper_bound = np.max(image)\n",
    "    img_as_float = image / upper_bound\n",
    "    img_as_float *= 2\n",
    "    img_as_float -= 1\n",
    "\n",
    "    markers = np.zeros(img_as_float.shape, dtype=np.uint)\n",
    "    markers[img_as_float < -0.90] = 1\n",
    "    markers[img_as_float > 0.90] = 2\n",
    "\n",
    "    return random_walker(img_as_float, markers, beta=10, mode='bf')\n",
    "\n",
    "\n",
    "def apply_flood_fill(image, starting_coordinates, tolerance):\n",
    "    upper_bound = np.max(image)\n",
    "    img_as_float = image / upper_bound\n",
    "    mask = flood(img_as_float, starting_coordinates, tolerance=tolerance)\n",
    "    mask = mask.astype('uint16')\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_threshold(image):\n",
    "    # thresh = threshold_mean(image)\n",
    "    return image > 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "denoised_images = data['denoised_images']['median']\n",
    "segmented_images = {}\n",
    "\n",
    "threshold_images = []\n",
    "random_walker_images = []\n",
    "fills = {}\n",
    "\n",
    "for median_image in denoised_images:\n",
    "    thresh = apply_threshold(median_image)\n",
    "    random_walker_img = apply_random_walker(median_image)\n",
    "\n",
    "    for tol in np.linspace(0.0, 0.2, 12):\n",
    "        str_tol = \"{:.2f}\".format(tol)\n",
    "\n",
    "        if str_tol not in fills:\n",
    "            fills[str_tol] = []\n",
    "\n",
    "        fill = apply_flood_fill(median_image, (71, 76), tol)\n",
    "        fills[str_tol].append(fill)\n",
    "\n",
    "    threshold_images.append(thresh)\n",
    "    random_walker_images.append(random_walker_img)\n",
    "\n",
    "segmented_images['threshold'] = threshold_images\n",
    "segmented_images['random_walker'] = random_walker_images\n",
    "segmented_images['flood_fill'] = fills\n",
    "\n",
    "data['segmented_images'] = segmented_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des résultats de segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hideCode": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b95f66e1dbf4f3a9b65229bcab58a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(SelectMultiple(index=(0, 1), layout=Layout(align_items='stretch', width='99%'), options=('Origi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_sets = [\n",
    "    {\n",
    "        'images': [image.pixel_array for image, _ in data['images']],\n",
    "        'title': 'Original',\n",
    "        'shown': True\n",
    "    },\n",
    "    {\n",
    "        'images': data['denoised_images']['median'],\n",
    "        'title': 'Median Filter',\n",
    "        'shown': True\n",
    "    },\n",
    "    {\n",
    "        'images': data['segmented_images']['threshold'],\n",
    "        'title': 'Threshold',\n",
    "        'shown': False\n",
    "    },\n",
    "    {\n",
    "        'images': data['segmented_images']['random_walker'],\n",
    "        'title': 'Random Walker',\n",
    "        'shown': False\n",
    "    }\n",
    "]\n",
    "\n",
    "for tol, fill in data['segmented_images']['flood_fill'].items():\n",
    "    image_sets.append({\n",
    "        'images': fill,\n",
    "        'title': 'Flood Fill Tol {}'.format(tol),\n",
    "        'shown': False\n",
    "    })\n",
    "\n",
    "nb_image_sets = len(image_sets)\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "fig = None\n",
    "\n",
    "with output:\n",
    "    plt.close(fig)\n",
    "    fig = plt.figure()\n",
    "\n",
    "# Hide figure header\n",
    "fig.canvas.header_visible = False\n",
    "ls = []\n",
    "current_image_slider = 0\n",
    "shown_image_sets = [image_set for image_set in image_sets if image_set['shown']]\n",
    "zoom = 2\n",
    "output_h, output_w = 0, 0\n",
    "\n",
    "# Executed on image slider change\n",
    "def update_images(change):\n",
    "    global shown_image_sets, ls, current_image_slider\n",
    "    current_image_slider = change.new\n",
    "\n",
    "    for idx, image in enumerate(ls):\n",
    "        image.set_data(shown_image_sets[idx]['images'][change.new])\n",
    "\n",
    "# Executed on zoom slider change\n",
    "def update_zoom(change):\n",
    "    global zoom, fig\n",
    "    zoom = change.new\n",
    "    fig.set_size_inches(output_w * zoom / 100, output_h * zoom / 100, forward=True)\n",
    "\n",
    "# Executed on image sets selection\n",
    "def update_image_sets(change):\n",
    "    global image_sets, ls, fig\n",
    "    ls.clear()\n",
    "\n",
    "    for image_set in image_sets: image_set['shown'] = False\n",
    "    \n",
    "    for idx in change.owner.index:\n",
    "        image_sets[idx]['shown'] = True\n",
    "    \n",
    "    plot_images(fig, image_sets)\n",
    "\n",
    "def plot_images(fig, image_sets):\n",
    "    global shown_image_sets, output_w, output_h, current_image_slider\n",
    "    shown_image_sets = [image_set for image_set in image_sets if image_set['shown']]\n",
    "    nb_shown_image_sets = len(shown_image_sets)\n",
    "    \n",
    "    ncols = 6 if nb_shown_image_sets > 6 else nb_shown_image_sets\n",
    "    nrows = int(np.ceil(nb_shown_image_sets / float(ncols)))\n",
    "    height, width = shown_image_sets[0]['images'][0].shape\n",
    "    output_h, output_w = (height * nrows), (width * ncols)\n",
    "    \n",
    "    # Clear previous figure\n",
    "    fig.clf()\n",
    "    # Set figure size based on the number of images\n",
    "    fig.set_size_inches(output_w * zoom / 100, output_h * zoom / 100, forward=True)\n",
    "    fig.set_dpi(100)\n",
    "    \n",
    "    for idx in range(nb_shown_image_sets):\n",
    "        ax = fig.add_subplot(nrows, ncols, idx + 1)\n",
    "        image = ax.imshow(shown_image_sets[idx]['images'][current_image_slider], cmap=plt.cm.gray)\n",
    "        ls.append(image)\n",
    "        \n",
    "        # Set title\n",
    "        ax.title.set_text(shown_image_sets[idx]['title'])\n",
    "        \n",
    "        # Hide grid and x, y ticks\n",
    "        ax.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    \n",
    "image_slider = widgets.IntSlider(\n",
    "    value=0, \n",
    "    min=0, max=47, step=1,\n",
    "    continuous_update=True,\n",
    "    description='Image',\n",
    "    layout=widgets.Layout(width='99%')\n",
    ")\n",
    "\n",
    "zoom_slider = widgets.FloatSlider(\n",
    "    value=zoom,\n",
    "    min=1, max=3, step=0.1,\n",
    "    continuous_update=False,\n",
    "    description='Zoom',\n",
    "    layout=widgets.Layout(width='99%')\n",
    ")\n",
    "\n",
    "image_set_selection = widgets.SelectMultiple(\n",
    "    # Add all image sets as options \n",
    "    options=[image_set['title'] for image_set in image_sets],\n",
    "    # Select by default the ones that are set as 'shown'\n",
    "    value=[image_set['title'] for image_set in shown_image_sets],\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='99%', align_items='stretch')\n",
    ")\n",
    "\n",
    "image_slider.observe(update_images, 'value')\n",
    "zoom_slider.observe(update_zoom, 'value')\n",
    "image_set_selection.observe(update_image_sets, 'value')\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_images(fig, shown_image_sets)\n",
    "\n",
    "widgets.VBox([image_set_selection, output, image_slider, zoom_slider])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de segmentation sur l'image 16\n",
    "\n",
    "<img src=\"examples/segmentation_example.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En dépit des segmentations utilisées, nous avons retenu la méthode du Flood Fill puisque le Threshold et le Random Walker ne nous permettaient pas d'avoir une segmentation propre et correcte.\n",
    "\n",
    "En effet, le Threshold ne se fiait qu'à l'intensité du pixel ce qui prenait également les pixels trop proches en valeurs de gris (par exemple, le contour du crâne) et était donc trop sensible.  \n",
    "Quant au Random Walker, il affichait une sphère et n'isolait pas du tout l'anévrisme ce qui n'était pas du tout ce que nous voulions.\n",
    "\n",
    "Ainsi, le flood fill fut la seule méthode qui nous donna quelque chose de convenable à la vue des résultats que nous pouvons observer.  \n",
    "Cette méthode a cependant le désavantage de nécessiter la sélection d'une « graine » (seed) pour commencer le flood fill. Celle-ci peut être sélectionnée par clic de souris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation par Flood Fill\n",
    "\n",
    "Dans un premier temps, nous avons créé une interface permettant de cliquer sur une zone de l'image afin de définir la graine du flood fill.  \n",
    "L'algorithme de flood fill n'est disponible qu'en 2D. Nous travaillons ici avec 48 images 2D et cette segmentation doit être effectuée pour chacune des coupes, il faut donc convertir cet algorithme pour qu'il fonctionne sur plusieurs images tout en gardant une connexité de la segmentation.\n",
    "\n",
    "## Première solution\n",
    "\n",
    "\n",
    "### Principe \n",
    "\n",
    "Le flood fill est effectué sur une image, nous obtenons un masque que l'on applique à l'image précédente/suivante.\n",
    "À partir des valeurs de gris contenues dans ce masque, nous calculons la moyenne des pixels et déterminons la nouvelle graine parmi les pixels proches de cette moyenne avec une certaine tolérance.\n",
    "Ainsi, le masque calculé pour l'image 16 sera appliqué à l'image 17, puis une nouvelle graine est déterminée à partir de ces valeurs. L'utilisation du masque déjà calculé sur la prochaine image permet d'assurer la connexité de la segmentation - en effet, le choix de la graine ne peut se faire que parmi les points communs aux deux images. Ce procédé fonctionne également dans le sens inverse : le masque de l'image 16 est appliqué à l'image 15, puis celui de l'image 15 à l'image 14 et ainsi de suite.\n",
    "\n",
    "### Problèmes\n",
    "\n",
    "L'approche par moyenne de valeur de gris pose un problème : cette moyenne change graduellement à mesure que l'on progresse dans les images. Ceci est dû à la fois à la tolérance du flood fill qui permet d'étendre le masque au-delà de la valeur de la graine initiale, mais également et surtout à la méthode de choix de la nouvelle graine. Le masque `n - 1` étant appliqué à l'image `n`, il se peut que l'on retrouve soudainement des valeurs de gris beaucoup plus sombres que celles de départ, et la moyenne s'en verrait alors fortement impactée.\n",
    "C'est ce que nous observons sur la vidéo ci-dessous lorsque nous approchons du début de la série d'images.\n",
    "\n",
    "### Résultats\n",
    "\n",
    "<video src=\"examples/first_flood_fill.webm\" type=\"video/webm\" controls loop></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième solution\n",
    "\n",
    "### Principe\n",
    "\n",
    "Le principe de sélection est le même : nous obtenons un masque appliqué à l'image précédente/suivante.  \n",
    "Cette fois-ci, plutôt que de sélectionner la nouvelle graine en calculant la moyenne des niveaux de gris, on la sélectionne par le biais d'une tolérance par rapport à la valeur initiale de la précédente graine. Ainsi, si lors du premier flood fill, la graine avait une valeur de 300 alors la sélection de la graine de la prochaine image se fera par rapport à cette valeur, ± une tolérance configurable (**seed tolerance**). Cette méthode a pour avantage de ne pas dériver vers des valeurs plus sombres car nous n'introduisons plus de moyenne.  \n",
    "De plus, afin que la sélection de la graine se fasse parmi les points déterminés les plus proches de la graine initiale, nous effectuons également une mesure de distance entre la graine initiale et toutes les graines candidates possibles (distance Euclidienne).  \n",
    "Nous obtenons alors deux critères de sélection de la nouvelle graine : la valeur de gris et la distance à la graine initiale. Nous effectuons un tri basé sur ces deux critères, en privilégiant toutefois la sélection par valeur de gris ce qui nous donne alors un certain nombre de nouvelles graines triées en fonction de leur couleur puis de leur distance. Parmi celles-ci, nous prenons alors la première graine.\n",
    "\n",
    "\n",
    "Nous appelons cet algorithme « Flood Fill évolutif ».\n",
    "\n",
    "### Avantages\n",
    "\n",
    "Le premier avantage de cette méthode est la garantie que l'on ne dérive pas vers des valeurs plus sombres ce qui nous permet de conserver une segmentation propre et ne contenant que les éléments qui nous intéressent.  \n",
    "Le deuxième avantage est simplement la reproducibilité des résultats. En effet, là où la première solution effectuait une sélection aléatoire parmi les graines candidates, nous sélectionnons ici la graine en nous basant sur deux critères. Ainsi, une segmentation effectuée à partir de la même image et des mêmes coordonnées donnera toujours le même résultat, ce qui n'était pas garanti précédemment.\n",
    "\n",
    "### Résultats\n",
    "\n",
    "<video src=\"examples/second_flood_fill.webm\" type=\"video/webm\" controls loop></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette interface n'est complètement fonctionnelle qu'en dehors d'un Jupyter Notebook.  \n",
    "Nous pouvons en voir un aperçu ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45619b41ee11417b8fd4a4d7acf19e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "denoised_images = data['denoised_images']['median']\n",
    "images = data['images']\n",
    "\n",
    "subplots_slider(\n",
    "    [['Original', [image.pixel_array for image, _ in images], {'type': 'original'}],\n",
    "     ['Median Filter', denoised_images, {'type': 'median_filter'}],\n",
    "     ['Mask', [np.zeros(denoised_images[0].shape)] * len(denoised_images), {'type': 'flood_fill', 'flood_fill_tolerance': globals.flood_fill_tolerance, 'seed_tolerance': globals.seed_tolerance}],\n",
    "     ['Result', [np.zeros(denoised_images[0].shape)] * len(denoised_images), {'type': 'result'}],\n",
    "     ['Skeleton', [np.zeros(denoised_images[0].shape)] * len(denoised_images), {'type': 'skeleton'}]],\n",
    "    click_handler=select_region, zoom=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélections multiples\n",
    "\n",
    "L'algorithme de Flood Fill étant un algorithme à croissance de région connexe, une seule sélection ne nous permet pas d'obtenir la totalité de la segmentation.\n",
    "Il a donc fallu modifier l'interface afin d'ajouter la possibilité de créer plusieurs segmentations qui sont ensuite fusionnées afin d'obtenir une segmentation finale.  \n",
    "Chaque segmentation peut avoir des paramètres de tolérance différents en changeant simplement les valeurs avant d'effectuer une nouvelle segmentation.  \n",
    "Il est également possible de supprimer une segmentation qui aurait par exemple mené à de mauvais résultats en cliquant sur le bouton `X`  \n",
    "Nous obtenons finalement dans ce cas six segmentations qui sont toutes connexes. Il est cependant possible qu'elles ne soient pas connexes entre elles car on pourrait segmenter des parties non liées.\n",
    "\n",
    "<img src=\"examples/six_segmentations.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de l'outil\n",
    "\n",
    "<video src=\"examples/demo_tool.webm\" type=\"video/webm\" controls loop></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de la segmentation en 3D\n",
    "\n",
    "En utilisant l'outil de visualisation 3Dicom, nous avons pu charger toutes les images générées par notre outil de segmentation et visualiser l'anévrisme géant ainsi que le tronc basilaire et les carotides.\n",
    "\n",
    "<video src=\"examples/3d_segmentation.webm\" type=\"video/webm\" controls loop></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du squelette\n",
    "\n",
    "Maintenant que nous avons obtenu une segmentation des parties nous intéressant, il nous faut désormais créer le squelette de cette segmentation.  \n",
    "Obtenir celui-ci ne revient finalement qu'à effectuer une érosion maximale de morphologie sur les images, lorsque celles-ci n'ont pas de lien entre elles.  \n",
    "Dans notre cas, nous souhaitons obtenir un squelette 3D, et simplement effectuer cette érosion sur chaque coupe en 2D donne de mauvais résultats.  \n",
    "Le paquet `skimage` propose une fonction nommée « skeletonize_3d » qui prend en entrée un tableau 3D d'images 2D et effectue cette squelettonisation sur l'ensemble des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_skeleton_3d(mask, factor, dilation_kernel=None):\n",
    "    height, width = mask[0].shape\n",
    "    dsize = (width * factor, height * factor)\n",
    "    new_mask = [cv2.resize(image_mask, dsize, cv2.INTER_NEAREST) for image_mask in mask]\n",
    "\n",
    "    skeletonized_mask = np.array([skeleton / 255 for skeleton in skeletonize_3d(np.array(new_mask))]).astype('uint8')\n",
    "\n",
    "    if dilation_kernel is not None:\n",
    "        skeletonized_mask = [skimage.morphology.binary_dilation(skeleton, dilation_kernel) for skeleton in skeletonized_mask]\n",
    "\n",
    "    return np.array(skeletonized_mask).astype('uint16') * globals.max_gray_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons la fonction `skeletonize_3d` sur le masque binaire car celle-ci n'accepte que des images en binaire.  \n",
    "Dans un premier temps, nous obtenions un squelette très peu visible de par les faibles dimensions de nos images (150x192), nous avions alors décidé de redimensionner le masque binaire pour augmenter les dimensions du squelette.  \n",
    "Hélas les résultats étaient très différents de ceux produits par la squelettonisation des images originales avec l'apparition de multiples branches qu'il aurait alors fallu ébarbuler.  \n",
    "Nous avons alors décidé de garder le squelette des images de taille originale.\n",
    "\n",
    "## Affichage des segmentations et du squelette\n",
    "\n",
    "<img src=\"examples/six_segmentations_plus_skeleton.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage du squelette 3D par Fiji\n",
    "\n",
    "L'affichage en 2D des images du squelette n'a que peu de sens, ces images étant été générées par un algortihme 3D. Nous avons donc importé la liste des nouvelles images sur Fiji via « File -> Import -> Image Sequence » et selectionné l'une des images que nous avons enregistrées.  \n",
    "Fiji s'occupait alors d'importer les images et il nous restait plus qu'à afficher les images en 3D par l'utilisation de « Image -> Stacks -> 3D project ». Hélas, le squelette s'en retrouve extrêmement pixelisé à cause de la faible dimension des images.  \n",
    "Voici le résultat :\n",
    "\n",
    "<img src=\"examples/skeleton_fiji.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage du squelette 3D par 3Dicom\n",
    "\n",
    "<video src=\"examples/3d_skeleton.webm\" type=\"video/webm\" controls loop></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse du squelette via FiJi\n",
    "\n",
    "## Diamètre de l'anévrisme\n",
    "\n",
    "Malgré les faibles dimensions du squelette, nous pouvons tout de même parvenir à analyser quelques détails. En effet, on peut même observer l'anévrisme. Pour davantage de clarté, nous allons colorier les pixels en blanc qui montrent donc l'anévrisme. Il se situe au sein d'un canal et nous pouvons ainsi l'identifier par une simple observation.  \n",
    "Pour calculer la taille de l'anévrisme, nous allons calculer le nombre de pixels qui définissent sa taille ainsi que récupérer le « Pixel Spacing » et la « Slice Thickness » pour obtenir la taille en mm de chaque pixel.  \n",
    "L'image ci-dessous correspond à la projection 2D de l'image 3D du squelette selon l'axe de rotation Y. Nous ne pouvons alors observer sur cette image que la largeur et la hauteur, et non la profondeur.\n",
    "\n",
    "<img src=\"examples/anevrism_white_skeleton.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions d'un voxel\n",
      "\n",
      "Largeur (x) : 1.146 mm\n",
      "Hauteur (y) : 1.146 mm\n",
      "Profondeur (z) : 1.1 mm\n"
     ]
    }
   ],
   "source": [
    "ConstPixelSpacing = []\n",
    "for patient in ds.patient_records:\n",
    "    # Find all the STUDY records for the patient\n",
    "    studies = [ii for ii in patient.children if ii.DirectoryRecordType == \"STUDY\"]\n",
    "\n",
    "    for study in studies:\n",
    "        # Find all the SERIES records in the study\n",
    "        all_series = [ii for ii in study.children if ii.DirectoryRecordType == \"SERIES\"]\n",
    "\n",
    "        for series in all_series:\n",
    "            ConstPixelSpacing = (float(img.PixelSpacing[0]), float(img.PixelSpacing[1]), float(img.SliceThickness))\n",
    "\n",
    "print(\"Dimensions d'un voxel\\n\\nLargeur (x) : {} mm\\nHauteur (y) : {} mm\\nProfondeur (z) : {} mm\".format(round(ConstPixelSpacing[0], 3), round(ConstPixelSpacing[1], 3), round(ConstPixelSpacing[2], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons ainsi 1.1458 mm comme largeur et hauteur de pixel par le biais du code python ci-dessus permettant de récupérer les informations contenues dans l'en-tête des images DICOM.  \n",
    "Il ne nous reste alors plus qu'à compter le nombre de pixels - celui-ci étant relativement faible - sur le squelette de l'anévrisme.  \n",
    "On trouve alors les mesures maximales suivantes : 4 pixels en largeur et 5 pixels en hauteur.  \n",
    "\n",
    "Nous obtenons alors :  \n",
    "4 x pixel spacing = 4 x 1.1458 = 4.5832 mm en largeur  \n",
    "5 x pixel spacing = 5 x 1.1458 = 5.7290 mm en hauteur  \n",
    "\n",
    "Ces valeurs ne correspondent qu'aux dimensions du squelette et non aux dimensions réelles de l'anévrisme. Pour obtenir les valeurs réelles, il faudrait alors faire correspondre la segmentation obtenue avec le squelette par le biais d'une carte de distance.\n",
    "\n",
    "## Diamètre en entrée des canaux\n",
    "\n",
    "Sachant que nous n'avons qu'un seul pixel en entrée au niveau des canaux, il nous suffit alors de calculer la taille d'un pixel qui se trouve être :\n",
    "\n",
    "1 x pixel spacing = 1 x 1.1458 = 1.1458 mm en hauteur/largeur\n",
    "\n",
    "## Aire et périmètre de l'anévrisme\n",
    "\n",
    "Grâce à Fiji, nous pouvons ensuite sélectionner la couleur blanche grâce à l'outil \"Wand (tracing) tool\" et sélectionner la zone pour permettre de sélectionner uniquement l'anévrisme. Nous allons ensuite utiliser « Analyze -> Set Measurement » et sélectionner les options suivantes :\n",
    "\n",
    "<img src=\"examples/option_fiji_measurement.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que la sélection est faite et que les différentes options sont sélectionnées, nous cliquons sur « Analyze -> Measure » qui nous permet de lancer la mesure et obtenir alors les mesures de la zone que nous avons selectionnée. Ainsi, nous obtenons le tableau suivant qui nous permet d'obtenir l'aire et le périmètre du squelette de l'anévrisme que nous avons sélectionné.  \n",
    "Nous obtenons ainsi une aire de 18.381 mm ainsi qu'un périmètre de 15.255 mm grâce aux résultats cités précédemment.\n",
    "\n",
    "<img src=\"examples/measure_fiji.png\" align=\"left\" />"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
