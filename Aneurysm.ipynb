{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anévrisme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquets nécessaires\n",
    "\n",
    "ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import copy\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interactive\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture du DICOMDIR et traitement des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous avons recherché un outil en Python capable de lire des fichiers DICOM et d'en extraire les informations nécessaires. Le paquet `pydicom` permet ceci.\n",
    "\n",
    "<!-- Description de l'installation -->\n",
    "\n",
    "Une fois ce paquet installé, nous pouvons lire notre jeu de données. Celui-ci contient des informations à plusieurs niveaux : pour chaque patient, il peut y avoir une ou plusieurs expérience(s) contenant chacune une ou plusieurs série(s) d'images. Dans notre cas, nous n'avons qu'une seule série. Nous récupérons les chemins de ces images puis les lisons avec la fonction `dcmread` du paquet `pydicom`.\n",
    "\n",
    "<!-- On a remarqué que sur les 500 et quelques images qu'on a, il y a une répétition toutes les 48 images -->\n",
    "\n",
    "Ces images sont en niveaux de gris sur 16 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"ImgTP/Ge1CaroG/MR_3DPCA\"\n",
    "ds = load_dataset(dataset_path)\n",
    "\n",
    "# 0018,1090  Cardiac Number of Images: 12\n",
    "nb_image_sets = 12\n",
    "\n",
    "# Select the first image set (must be < 12)\n",
    "starting_image_set = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# Iterate through the PATIENT records\n",
    "for patient in ds.patient_records:\n",
    "    # Find all the STUDY records for the patient\n",
    "    studies = [ii for ii in patient.children if ii.DirectoryRecordType == \"STUDY\"]\n",
    "    \n",
    "    data[patient.PatientName] = {}\n",
    "\n",
    "    for study in studies:\n",
    "        # Find all the SERIES records in the study\n",
    "        all_series = [ii for ii in study.children if ii.DirectoryRecordType == \"SERIES\"]\n",
    "        \n",
    "        data[patient.PatientName][study.StudyID] = {}\n",
    "\n",
    "        for series in all_series:\n",
    "            data[patient.PatientName][study.StudyID][series.SeriesNumber] = {}\n",
    "            \n",
    "            # Find all the IMAGE records in the series\n",
    "            images = [ii for ii in series.children if ii.DirectoryRecordType == \"IMAGE\"]\n",
    "            \n",
    "            # Get the absolute file path to each instance\n",
    "            # Each IMAGE contains a relative file path to the root directory\n",
    "            elems = [ii[\"ReferencedFileID\"] for ii in images]\n",
    "            # Make sure the relative file path is always a list of str\n",
    "            paths = [[ee.value] if ee.VM == 1 else ee.value for ee in elems]\n",
    "            paths = [Path(*p) for p in paths]\n",
    "\n",
    "            images = []\n",
    "\n",
    "            i = 0\n",
    "            \n",
    "            total_images = len(paths)\n",
    "            max_images = int(total_images / nb_image_sets)\n",
    "            \n",
    "            # List the instance file paths\n",
    "            for idx in range(starting_image_set * max_images, (starting_image_set + 1) * max_images):\n",
    "                p = paths[idx]\n",
    "                img = dcmread(Path(dataset_path).joinpath(p))\n",
    "                images.append((img, p))\n",
    "                    \n",
    "            data[patient.PatientName][study.StudyID][series.SeriesNumber]['images'] = images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression du bruit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suppression du bruit peut s'effectuer par l'utilisation de différents filtres. Parmi ceux-ci on retrouve par exemple le filtre bilatéral, le débruitage par patchs (Non-Local Means) ou encore le filtre médian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_nl_means, estimate_sigma, denoise_bilateral\n",
    "\n",
    "def apply_non_local_means(img, kernel=5, window_search=13):\n",
    "    # Retain original data type\n",
    "    orig_dtype = img.pixel_array.dtype\n",
    "\n",
    "    # Convert from [0; max] to [0; 1] as it is required by denoise_nl_means\n",
    "    upper_bound = np.max(img.pixel_array)\n",
    "    img_as_float = img.pixel_array / upper_bound\n",
    "\n",
    "    sigma_est = np.mean(estimate_sigma(img_as_float, multichannel=False))\n",
    "\n",
    "    new_img = denoise_nl_means(img_as_float, h=sigma_est, fast_mode=True, patch_size=kernel,\n",
    "                               patch_distance=window_search)\n",
    "\n",
    "    # Convert back to [0; max]\n",
    "    new_img *= upper_bound\n",
    "\n",
    "    return new_img.astype(orig_dtype)\n",
    "\n",
    "\n",
    "def apply_bilateral_filtering(img, d=15, sigmacolor=75, sigmacoordinate=75):\n",
    "    # Retain original data type\n",
    "    orig_dtype = img.pixel_array.dtype\n",
    "\n",
    "    # Convert from [0; max] to [0; 1] as it is required by denoise_nl_means\n",
    "    upper_bound = np.max(img.pixel_array)\n",
    "    img_as_float = img.pixel_array / upper_bound\n",
    "\n",
    "    new_img = denoise_bilateral(img_as_float, win_size=d, sigma_color=sigmacolor, sigma_spatial=sigmacoordinate)\n",
    "\n",
    "    # Convert back to [0; max]\n",
    "    new_img *= upper_bound\n",
    "\n",
    "    return new_img.astype(orig_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patientName, patientData in data.items():\n",
    "    for studyId, studyData in patientData.items():\n",
    "        for seriesId, seriesData in studyData.items():\n",
    "            images = seriesData['images']\n",
    "            denoised_images = []\n",
    "            \n",
    "            for image, p in images:\n",
    "                median = apply_simple_denoise(image, kernel_size=3)\n",
    "\n",
    "                denoised_images.append(median)\n",
    "                \n",
    "            data[patientName][studyId][seriesId]['denoised_images'] = denoised_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patientName, patientData in data.items():\n",
    "    for studyId, studyData in patientData.items():\n",
    "        for seriesId, seriesData in studyData.items():\n",
    "            denoised_images = data[patientName][studyId][seriesId]['denoised_images']\n",
    "            threshold_images = []\n",
    "            random_walker_images = []\n",
    "            fills = {}\n",
    "    \n",
    "            for median_image in denoised_images:\n",
    "                thresh = apply_threshold(median_image)\n",
    "                random_walker = apply_random_walker(median_image)\n",
    "\n",
    "                for tol in np.linspace(0.2, 0.4, 12):\n",
    "                    str_tol = \"{:.2f}\".format(tol)\n",
    "\n",
    "                    if str_tol not in fills:\n",
    "                        fills[str_tol] = []\n",
    "\n",
    "                    fill = apply_flood_fill(median_image, (76, 69), tol)\n",
    "                    fills[str_tol].append(fill)\n",
    "\n",
    "                threshold_images.append(thresh)\n",
    "                random_walker_images.append(random_walker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection des méthodes de segmentation (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_methods = [\n",
    "    'Flood',\n",
    "    'Random Walker'\n",
    "]\n",
    "\n",
    "segmentation_method_widget = widgets.Dropdown(\n",
    "    options=segmentation_methods,\n",
    "    value='Flood',\n",
    "    description='Segmentation method:',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%html\n",
    "# <style>\n",
    "# div.jupyter-widgets-view:nth-child(1) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) {display: initial;}\n",
    "# </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du plot et des widgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sets = [\n",
    "    {\n",
    "        'images': [image.pixel_array for image, _ in images],\n",
    "        'title': 'Original',\n",
    "        'shown': True\n",
    "    },\n",
    "    {\n",
    "        'images': denoised_images,\n",
    "        'title': 'Median Filter',\n",
    "        'shown': False\n",
    "    },\n",
    "    {\n",
    "        'images': threshold_images,\n",
    "        'title': 'Threshold',\n",
    "        'shown': False\n",
    "    },\n",
    "    {\n",
    "        'images': random_walker_images,\n",
    "        'title': 'Random Walker',\n",
    "        'shown': False\n",
    "    }\n",
    "]\n",
    "\n",
    "for tol in fills:\n",
    "    image_sets.append({\n",
    "        'images': fills[tol],\n",
    "        'title': 'Flood Fill Tol {}'.format(tol),\n",
    "        'shown': False\n",
    "    })\n",
    "\n",
    "nb_image_sets = len(image_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = widgets.Output()\n",
    "\n",
    "fig = None\n",
    "\n",
    "with output:\n",
    "    plt.close(fig)\n",
    "    fig = plt.figure()\n",
    "\n",
    "# Hide figure header\n",
    "fig.canvas.header_visible = False\n",
    "ls = []\n",
    "current_image_slider = 0\n",
    "shown_image_sets = [image_set for image_set in image_sets if image_set['shown']]\n",
    "zoom = 1\n",
    "output_h, output_w = 0, 0\n",
    "\n",
    "# Executed on image slider change\n",
    "def update_images(change):\n",
    "    global shown_image_sets, ls\n",
    "    current_image_slider = change.new\n",
    "\n",
    "    for idx, image in enumerate(ls):\n",
    "        image.set_data(shown_image_sets[idx]['images'][change.new])\n",
    "\n",
    "# Executed on zoom slider change\n",
    "def update_zoom(change):\n",
    "    global zoom, fig\n",
    "    zoom = change.new\n",
    "    fig.set_size_inches(output_w * zoom / 100, output_h * zoom / 100, forward=True)\n",
    "\n",
    "# Executed on image sets selection\n",
    "def update_image_sets(change):\n",
    "    global image_sets, ls, fig\n",
    "    ls.clear()\n",
    "\n",
    "    for image_set in image_sets: image_set['shown'] = False\n",
    "    \n",
    "    for idx in change.owner.index:\n",
    "        image_sets[idx]['shown'] = True\n",
    "    \n",
    "    plot_images(fig, image_sets)\n",
    "\n",
    "def plot_images(fig, image_sets):\n",
    "    global shown_image_sets, output_w, output_h\n",
    "    shown_image_sets = [image_set for image_set in image_sets if image_set['shown']]\n",
    "    nb_shown_image_sets = len(shown_image_sets)\n",
    "    \n",
    "    ncols = int(np.ceil(np.sqrt(nb_shown_image_sets)))\n",
    "    nrows = int(np.ceil(nb_shown_image_sets / float(ncols)))\n",
    "    height, width = shown_image_sets[0]['images'][0].shape\n",
    "    output_h, output_w = (height * nrows) + 100, (width * ncols) + 100\n",
    "    \n",
    "    # Clear previous figure\n",
    "    fig.clf()\n",
    "    # Set figure size based on the number of images\n",
    "    fig.set_size_inches(output_w * zoom / 100, output_h * zoom / 100, forward=True)\n",
    "    fig.set_dpi(100)\n",
    "    \n",
    "    for idx in range(nb_shown_image_sets):\n",
    "        ax = fig.add_subplot(nrows, ncols, idx + 1)\n",
    "        image = ax.imshow(shown_image_sets[idx]['images'][current_image_slider], cmap=plt.cm.gray)\n",
    "        ls.append(image)\n",
    "        \n",
    "        # Set title\n",
    "        ax.title.set_text(shown_image_sets[idx]['title'])\n",
    "        \n",
    "        # Hide grid and x, y ticks\n",
    "        ax.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    \n",
    "image_slider = widgets.IntSlider(\n",
    "    value=0, \n",
    "    min=0, max=47, step=1,\n",
    "    continuous_update=True,\n",
    "    description='Image',\n",
    "    layout=widgets.Layout(width='99%')\n",
    ")\n",
    "\n",
    "zoom_slider = widgets.FloatSlider(\n",
    "    value=1,\n",
    "    min=1, max=3, step=0.1,\n",
    "    continuous_update=False,\n",
    "    description='Zoom',\n",
    "    layout=widgets.Layout(width='99%')\n",
    ")\n",
    "\n",
    "image_set_selection = widgets.SelectMultiple(\n",
    "    # Add all image sets as options \n",
    "    options=[image_set['title'] for image_set in image_sets],\n",
    "    # Select by default the ones that are set as 'shown'\n",
    "    value=[image_set['title'] for image_set in shown_image_sets],\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='99%', align_items='stretch')\n",
    ")\n",
    "\n",
    "image_slider.observe(update_images, 'value')\n",
    "zoom_slider.observe(update_zoom, 'value')\n",
    "image_set_selection.observe(update_image_sets, 'value')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ce650fa7294132b8b030afa46a5487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(SelectMultiple(index=(0,), layout=Layout(align_items='stretch', width='99%'), options=('Origina…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(fig, shown_image_sets)\n",
    "\n",
    "widgets.VBox([image_set_selection, output, image_slider, zoom_slider])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}